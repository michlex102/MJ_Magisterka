{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57d2ae4-9b5b-4c96-812b-fdd968d0c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba komentarzy do analizy (niepuste, NPS 7-8): 9208\n",
      "Model załadowany\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gotowe! Wyniki zapisano do: ../Data/nps_sentiment_results.csv\n",
      "                                   NPS & OSAT comment       Sentiment_Flag\n",
      "0                                          Easy going  Neutral_or_Positive\n",
      "1   Not sure what was going on but it took over an...  Neutral_or_Positive\n",
      "3                                      Cena za wysoka  Neutral_or_Positive\n",
      "9                                Opóźnienie w wylocie  Neutral_or_Positive\n",
      "11                              Good reliable on time  Neutral_or_Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Był problem z długością ścieżki stąd wymuszam ukrórcenie poprzez instalacje modelu w folderze bezpośrednio na dysku C\n",
    "custom_cache = \"C:/hf_cache\"\n",
    "if not os.path.exists(custom_cache):\n",
    "    os.makedirs(custom_cache)\n",
    "\n",
    "df = pd.read_csv('../Data/NPS_2025.csv', sep=';', keep_default_na=False, na_values=[''], low_memory=False)\n",
    "\n",
    "# NPS 7 lub 8\n",
    "subset = df[\n",
    "    (df['NPS & OSAT comment'].notna()) & \n",
    "    (df['NPS & OSAT comment'] != '') &\n",
    "    (df['NPS & OSAT comment'] != 'N/A') &\n",
    "    (df['NPS'].isin([7, 8]))\n",
    "][['NPS', 'NPS & OSAT comment']].copy()\n",
    "\n",
    "print(f\"Liczba komentarzy do analizy (niepuste, NPS 7-8): {len(subset)}\")\n",
    "\n",
    "# ładowanie modelu XLM-RoBERTa\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=custom_cache, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, cache_dir=custom_cache)\n",
    "    \n",
    "    # Zamiast na CPU tworzę pipeline na GPU aby było szybciej\n",
    "    classifier = pipeline(\n",
    "        \"sentiment-analysis\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        device = 0,  # W przypadku braku GPU proszę zamienić na -1, czyli CPU\n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )\n",
    "    print(\"Model załadowany\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Błąd ładowania modelu: {e}\")\n",
    "    # W przypadku błędu związanego z nieutworzeniem folderu na dysku C zatrzymuję kod już w tym momencie\n",
    "    raise e\n",
    "    \n",
    "# Przygotowanie danych (konwersja kolumny na listę)\n",
    "# Zamiana na listę stringów jest konieczna dla pipeline'u\n",
    "comments_list = subset['NPS & OSAT comment'].astype(str).tolist()\n",
    "\n",
    "results = []\n",
    "batch_size = 16\n",
    "print(f\"Rozpoczynam analizę {len(comments_list)} komentarzy...\")\n",
    "# Iteracja po liście z krokiem 'batch_size'\n",
    "for i in range(0, len(comments_list), batch_size):\n",
    "    # Wybór tekstów\n",
    "    batch = comments_list[i : i + batch_size]\n",
    "    # Model przetwarza całą paczkę na raz\n",
    "    predictions = classifier(batch)\n",
    "    # Zapis wyników z tej paczki\n",
    "    for out in predictions:\n",
    "        label = out['label']\n",
    "        if label == 'negative': \n",
    "            results.append('Negative')\n",
    "        else:\n",
    "            results.append('Neutral_or_Positive')\n",
    "            \n",
    "# Przypisanie wyników z powrotem do DataFrame\n",
    "subset['Sentiment_Flag'] = results\n",
    "\n",
    "# Zapis pliku do folderu Data\n",
    "output_path = '../Data/nps_sentiment_results.csv'\n",
    "subset[['Sentiment_Flag']].to_csv(output_path, index=True)\n",
    "\n",
    "print(f\"Gotowe! Wyniki zapisano do: {output_path}\")\n",
    "print(subset[['NPS & OSAT comment', 'Sentiment_Flag']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cd6d74-5a7c-495b-8c2a-5ec01bab36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Flag\n",
      "Neutral_or_Positive    5200\n",
      "Negative               4008\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(subset['Sentiment_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a566214-cef5-4900-b0ff-3a2742a2a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NPS                                 NPS & OSAT comment Sentiment_Flag\n",
      "19     7                    Too many low charter equipment.       Negative\n",
      "35     7  Nice flight. However old plane so impossible t...       Negative\n",
      "69     7  Jakaś stara baba zajęła moje miejsce i na kilk...       Negative\n",
      "93     8  I had a missed connection twice within 3  week...       Negative\n",
      "101    7                    Not a nice boarding experience.       Negative\n",
      "108    7  Inconvenience about PRG-WAW. There was 90 min ...       Negative\n",
      "135    8            wszystko OK, minus za lekkie spóźnienie       Negative\n",
      "146    7        Slightly delaying on flights but managable.       Negative\n",
      "187    7       Delay without, apparently, a serious reason.       Negative\n",
      "191    7  Not ok, because When I did the check in I coul...       Negative\n"
     ]
    }
   ],
   "source": [
    "# Filtrowanie i wyświetlenie pierwszych 10 wyników\n",
    "negative_subset = subset[subset['Sentiment_Flag'] == 'Negative']\n",
    "print(negative_subset.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MGR)",
   "language": "python",
   "name": "mgr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
