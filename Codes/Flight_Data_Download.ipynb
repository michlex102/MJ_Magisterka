{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd50448-d816-49fc-974a-5b3201547ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\folder_python\\envs\\mgr\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\folder_python\\envs\\mgr\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\folder_python\\envs\\mgr\\lib\\site-packages (from geopy) (2.1)\n",
      "Requirement already satisfied: colorama in c:\\folder_python\\envs\\mgr\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c59c561-0d8e-486d-9c05-0acc63ae203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b81983-8644-4454-8971-7c5f70ae75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja stałych - położenia Warszawy oraz nazw plików\n",
    "LAT_WAW = 52.159499362\n",
    "LONG_WAW = 20.966996132\n",
    "DATE_URL_PART = \"2025/12/01\" # Format do URL ADSBExchange\n",
    "DATE_FILENAME = \"20251201\"   # Format do nazwy pliku lokalnego\n",
    "\n",
    "# Ustawienie ścieżek\n",
    "#base_dir = os.path.dirname(os.path.abspath(__file__)) #Dla .py\n",
    "base_dir = os.getcwd() #Dla jupytera\n",
    "arrivals_path = os.path.join(base_dir, '..', 'data', f'ax_arrivals_{DATE_FILENAME}.csv')\n",
    "output_path = os.path.join(base_dir, '..', 'data', f'loty_waw_8_23_{DATE_FILENAME}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a6432a-e76c-4110-9e96-4a0a4a78e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcje pomocnicze\n",
    "def download_json_to_pandas(url):\n",
    "    \"\"\"Pobiera JSON z ADSBExchange i zamienia na DataFrame\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        json_data = response.json()\n",
    "        # Dane o samolotach są w kluczu 'aircraft' lub 'ac' zależnie od wersji\n",
    "        aircraft_data = json_data.get('aircraft', []) or json_data.get('ac', [])\n",
    "        return pd.DataFrame(aircraft_data)\n",
    "    except Exception as e:\n",
    "        # Czasami pojedynczy plik może nie istnieć lub zerwać połączenie\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def haversine_distance(row):\n",
    "    \"\"\"Oblicza dystans do Okęcia (wymaga kolumn 'lat', 'lon')\"\"\"\n",
    "    if pd.isna(row['lat']) or pd.isna(row['lon']):\n",
    "        return None\n",
    "    return geodesic((row['lat'], row['lon']), (LAT_WAW, LONG_WAW)).kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7ac977-b891-4209-bd1d-2771e854cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista kolumn do zachowania\n",
    "COLS_TO_KEEP = [\n",
    "    'hex', 'flight', 'category', 'lat', 'lon', \n",
    "    'alt_baro', 'alt_geom', 'gs', 'track', \n",
    "    'geom_rate', 'track_rate', 'seen_pos',\n",
    "    'snapshot_time', 'distance_km'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419afaa4-c99d-45ac-bd14-2eaced11ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytywanie listy przylotów/odlotów (White-list)...\n",
      "Znaleziono 459 unikalnych lotów powiązanych z EPWA w pliku planowym.\n",
      "Generowanie listy czasów do pobrania (08:00 - 10:00)...\n",
      "Liczba snapshotów do pobrania: 10801\n"
     ]
    }
   ],
   "source": [
    "print(\"Wczytywanie listy przylotów/odlotów (White-list)...\")\n",
    "\n",
    "try:\n",
    "    df_arrivals = pd.read_csv(arrivals_path, low_memory=False)\n",
    "    \n",
    "    # Normalizacja callsign (usuwamy spacje)\n",
    "    if 'callsign' in df_arrivals.columns:\n",
    "        df_arrivals['callsign'] = df_arrivals['callsign'].astype(str).str.strip().str.upper()\n",
    "    elif 'flight' in df_arrivals.columns:\n",
    "        df_arrivals['callsign'] = df_arrivals['flight'].astype(str).str.strip().str.upper()\n",
    "        \n",
    "    # FILTRACJA: Tylko loty powiązane z Warszawą (EPWA)\n",
    "    # nie filtrujemy tu czasu, bierzemy cały dzień,\n",
    "    # żeby nie przegapić opóźnionych lotów.\n",
    "    mask_waw = (df_arrivals['dest'] == \"EPWA\") | (df_arrivals['orig'] == \"EPWA\")\n",
    "    df_waw = df_arrivals[mask_waw].copy()\n",
    "    \n",
    "    # Lista unikalnych znaków wywoławczych (np. LOT123)\n",
    "    unique_flights_to_waw = df_waw['callsign'].unique().tolist()\n",
    "    \n",
    "    print(f\"Znaleziono {len(unique_flights_to_waw)} unikalnych lotów powiązanych z EPWA w pliku planowym.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"BŁĄD: Nie znaleziono pliku {arrivals_path}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Generowanie listy czasów do pobrania (08:00 - 10:00)...\")\n",
    "\n",
    "start_time = datetime.strptime(\"080000\", \"%H%M%S\")\n",
    "end_time = datetime.strptime(\"230000\", \"%H%M%S\")\n",
    "time_intervals = []\n",
    "\n",
    "current = start_time\n",
    "while current <= end_time:\n",
    "    time_intervals.append(current.strftime(\"%H%M%S\"))\n",
    "    current += timedelta(seconds=5) # Pobieranie co 5 sekund\n",
    "\n",
    "print(f\"Liczba snapshotów do pobrania: {len(time_intervals)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf879e95-67fd-4cd3-96f9-88bc5346054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontener na wszystkie pobrane dane\n",
    "all_data_frames = []\n",
    "missed_downloads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3850ec6b-2ebe-4a9c-b14e-459461d9e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie równoległego pobierania dla 10801 snapshotów...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10801/10801 [1:07:21<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakończono! Zebrano dane z 10800 snapshotów.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Tworzymy sesję, aby reużywać połączenia TCP (bardzo ważne dla szybkości!)\n",
    "session = requests.Session()\n",
    "\n",
    "def download_and_process(time_str):\n",
    "    \"\"\"Funkcja pomocnicza do przetwarzania jednego pliku w osobnym wątku\"\"\"\n",
    "    url = f\"https://samples.adsbexchange.com/readsb-hist/{DATE_URL_PART}/{time_str}Z.json.gz\"\n",
    "    \n",
    "    try:\n",
    "        # Pobieranie danych przez sesję\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        json_data = response.json()\n",
    "        aircraft_data = json_data.get('aircraft', []) or json_data.get('ac', [])\n",
    "        df_snap = pd.DataFrame(aircraft_data)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if not df_snap.empty and 'flight' in df_snap.columns:\n",
    "        # Standaryzacja i filtrowanie (logika z Twojego oryginalnego kodu)\n",
    "        df_snap['flight'] = df_snap['flight'].astype(str).str.strip().str.upper()\n",
    "        df_snap = df_snap[df_snap['flight'].isin(unique_flights_to_waw)].copy()\n",
    "        \n",
    "        if not df_snap.empty:\n",
    "            df_snap['snapshot_time'] = time_str\n",
    "            df_snap = df_snap.dropna(subset=['lat', 'lon'])\n",
    "            \n",
    "            if not df_snap.empty:\n",
    "                # Obliczenia dystansu (haversine_distance z komórki nr 4)\n",
    "                df_snap['distance_km'] = df_snap.apply(haversine_distance, axis=1)\n",
    "                \n",
    "                # Wybór kolumn (COLS_TO_KEEP z komórki nr 5)\n",
    "                existing_cols = [c for c in COLS_TO_KEEP if c in df_snap.columns]\n",
    "                return df_snap[existing_cols]\n",
    "    return None\n",
    "\n",
    "print(f\"Rozpoczęcie równoległego pobierania dla {len(time_intervals)} snapshotów...\")\n",
    "\n",
    "# max_workers=20 oznacza 20 równoległych zapytań. \n",
    "# Jeśli masz bardzo szybki internet, możesz spróbować wartości 30 lub 40.\n",
    "with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "    # executor.map rozdziela zadania na wątki\n",
    "    results = list(tqdm(executor.map(download_and_process, time_intervals), total=len(time_intervals)))\n",
    "\n",
    "# Filtrujemy wyniki (usuwamy None) i przypisujemy do Twojej listy\n",
    "all_data_frames = [df for df in results if df is not None]\n",
    "\n",
    "print(f\"Zakończono! Zebrano dane z {len(all_data_frames)} snapshotów.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdc9044-8bf9-485a-a28f-40e8c2dc8ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Łączenie danych i zapisywanie...\n",
      "SUKCES! Zapisano 547822 punktów pomiarowych do pliku:\n",
      "C:\\Users\\Michał J\\Desktop\\MJ_mgr\\Codes\\..\\data\\loty_waw_8_23_20251201.csv\n",
      "  snapshot_time   flight        lat        lon  distance_km alt_baro\n",
      "0        080000   LOT16M  58.500000 -28.533300  3143.072981    37000\n",
      "1        080000   LOT3PK  56.017332 -11.097479  2121.332828    39000\n",
      "2        080000  TAP120Y  41.782589  -5.650997  2311.731328    36025\n",
      "3        080000   WZZ4LM  53.334709  -2.862959  1606.980074   ground\n",
      "4        080000  WZZ20CS  51.880793  -0.377312  1460.261310   ground\n"
     ]
    }
   ],
   "source": [
    "# Zapis wyników\n",
    "\n",
    "if all_data_frames:\n",
    "    print(\"Łączenie danych i zapisywanie...\")\n",
    "    master_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "    \n",
    "    # Zapis do pliku w folderze data\n",
    "    master_df.to_csv(output_path, index=False)\n",
    "    print(f\"SUKCES! Zapisano {len(master_df)} punktów pomiarowych do pliku:\")\n",
    "    print(output_path)\n",
    "    \n",
    "    print(master_df[['snapshot_time', 'flight', 'lat', 'lon', 'distance_km', 'alt_baro']].head())\n",
    "else:\n",
    "    print(\"Ostrzeżenie: Nie pobrano żadnych danych pasujących do kryteriów.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
